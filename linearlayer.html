<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Mạng Neural Đơn Giản với Các lớp Input và Output">

<title>Fashion_MNIST_Project - Linear Layer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Fashion_MNIST_Project - Linear Layer">
<meta property="og:description" content="Mạng Neural Đơn Giản với Các lớp Input và Output">
<meta property="og:image" content="https://nvtai040502.github.io/Fashion_MNIST_Project/01_linearlayer_files/figure-html/cell-4-output-1.png">
<meta property="og:site-name" content="Fashion_MNIST_Project">
<meta property="og:image:height" content="715">
<meta property="og:image:width" content="1059">
<meta name="twitter:title" content="Fashion_MNIST_Project - Linear Layer">
<meta name="twitter:description" content="Mạng Neural Đơn Giản với Các lớp Input và Output">
<meta name="twitter:image" content="https://nvtai040502.github.io/Fashion_MNIST_Project/01_linearlayer_files/figure-html/cell-4-output-1.png">
<meta name="twitter:image-height" content="715">
<meta name="twitter:image-width" content="1059">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Fashion MNIST</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/nvtai040502" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./linearlayer.html">Linear Layer</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Fashion MNIST</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./process.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Process Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linearlayer.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Linear Layer</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neuralnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Network</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regularization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNN</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./finetuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fine Tuning</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#previous-chapter-code" id="toc-previous-chapter-code" class="nav-link active" data-scroll-target="#previous-chapter-code">Previous Chapter Code</a></li>
  <li><a href="#forward-propagation" id="toc-forward-propagation" class="nav-link" data-scroll-target="#forward-propagation">Forward Propagation</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss Function</a></li>
  <li><a href="#optimization-algorithms" id="toc-optimization-algorithms" class="nav-link" data-scroll-target="#optimization-algorithms">Optimization Algorithms</a></li>
  <li><a href="#backward-propagation" id="toc-backward-propagation" class="nav-link" data-scroll-target="#backward-propagation">Backward Propagation</a></li>
  <li><a href="#altogether" id="toc-altogether" class="nav-link" data-scroll-target="#altogether">Altogether</a>
  <ul class="collapse">
  <li><a href="#use-sample-data" id="toc-use-sample-data" class="nav-link" data-scroll-target="#use-sample-data">Use Sample Data</a></li>
  <li><a href="#use-all-data" id="toc-use-all-data" class="nav-link" data-scroll-target="#use-all-data">Use All Data</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/nvtai040502/Fashion_MNIST_Project/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Linear Layer</h1>
</div>

<div>
  <div class="description">
    Mạng Neural Đơn Giản với Các lớp Input và Output
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="previous-chapter-code" class="level2">
<h2 class="anchored" data-anchor-id="previous-chapter-code">Previous Chapter Code</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download Data</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># constant for classes</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> [<span class="st">'T-shirt/top'</span>, <span class="st">'Trouser'</span>, <span class="st">'Pullover'</span>, <span class="st">'Dress'</span>, <span class="st">'Coat'</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Sandal'</span>, <span class="st">'Shirt'</span>, <span class="st">'Sneaker'</span>, <span class="st">'Bag'</span>, <span class="st">'Ankle Boot'</span>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> train_dataset.data</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train_dataset.targets</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into train &amp; valid set</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>valid_pct <span class="op">=</span> <span class="fl">.2</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>x_train, x_valid, y_train, y_valid <span class="op">=</span> train_test_split(x, y, test_size <span class="op">=</span> valid_pct)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalization </span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> min_max_scale(data, a<span class="op">=</span><span class="dv">0</span>, b<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the minimum and maximum values of the data</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    data_min <span class="op">=</span> data.<span class="bu">min</span>()</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    data_max <span class="op">=</span> data.<span class="bu">max</span>()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform Min-Max Scaling</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    data_norm <span class="op">=</span> (data <span class="op">-</span> data_min) <span class="op">/</span> (data_max <span class="op">-</span> data_min)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rescale the data to the [a, b] range</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    data_norm <span class="op">=</span> a <span class="op">+</span> data_norm <span class="op">*</span> (b <span class="op">-</span> a)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_norm</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>x_train_norm <span class="op">=</span> min_max_scale(x_train)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>x_valid_norm <span class="op">=</span> min_max_scale(x_valid)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset, DataLoader</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(x_tensor, y_tensor, batch_size, test):</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> TensorDataset(x_tensor, y_tensor)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> DataLoader(data, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="kw">not</span> test, drop_last<span class="op">=</span><span class="kw">not</span> test)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total Mini-Batches: </span><span class="sc">{</span><span class="bu">len</span>(data_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Shape of Each Mini-Batch: </span><span class="sc">{</span>x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_loader</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> load_data(x_train_norm, y_train, batch_size<span class="op">=</span>batch_size, test <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>valid_loader <span class="op">=</span> load_data(x_valid_norm, y_valid, batch_size<span class="op">=</span>batch_size, test<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total Mini-Batches: 375
Shape of Each Mini-Batch: torch.Size([128, 28, 28])

Total Mini-Batches: 94
Shape of Each Mini-Batch: torch.Size([128, 28, 28])
</code></pre>
</div>
</div>
<p>Trong đoạn mã trên, tôi chỉ loại bỏ các câu lệnh print không cần thiết và giữ nguyên phần phần còn lại của đoạn code như trong chương trước đó.</p>
</section>
<section id="forward-propagation" class="level2">
<h2 class="anchored" data-anchor-id="forward-propagation">Forward Propagation</h2>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first min batch of data from the train_loader</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>sample_x, sample_y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape X to match the neural network model input size (flatten)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>sample_x <span class="op">=</span> sample_x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert X to the appropriate data type (float32)</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>sample_x <span class="op">=</span> sample_x.to(torch.float32)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of output classes</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>n_out <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize weight and bias tensors with requires_grad=True</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>weight <span class="op">=</span> torch.randn(<span class="dv">784</span>, n_out, requires_grad <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> torch.zeros(n_out, requires_grad <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform the forward pass through the neural network</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>sample_out <span class="op">=</span> sample_x <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the shape of the output</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>sample_out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>torch.Size([128, 10])</code></pre>
</div>
</div>
<p><strong>Linear Layer: Một trong những Mô hình Cơ bản của Deep Learning</strong></p>
<p>Linear Layer (Lớp Tuyến tính) là một trong những mô hình cơ bản nhất trong lĩnh vực Deep Learning. Mô hình này chỉ cần một đầu vào đã được làm phẳng (flatten), một trọng số (weight) và một sai số (bias) để hoạt động. Các thành phần này hoạt động cùng nhau để tạo ra dự đoán cho biến mục tiêu của dự án.</p>
<p><strong>Công thức Linear Layer:</strong></p>
<p>Dự đoán (Prediction) được tính bằng công thức sau:</p>
<p><span class="math display">\[ \text{Prediction} = (\text{Input} \cdot \text{Weight}) + \text{Bias} \]</span></p>
<p>Trong đó:</p>
<ul>
<li><p>Prediction: Kết quả đầu ra mong muốn.</p></li>
<li><p>Input: là vector đầu vào đã được làm phẳng.</p></li>
<li><p>Weight: là trọng số cần tìm để tối ưu hóa mô hình.</p></li>
<li><p>Bias: là giá trị điều chỉnh cho dự đoán.</p></li>
</ul>
<p>Trong thực tế, trọng số (weight) thường được khởi tạo ngẫu nhiên theo phân phối đồng nhất (uniform distribution), và Bias thường bắt đầu từ giá trị 0.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots with 2 rows and 4 columns</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through each subplot</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axs.flatten():</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select a random index from the batch</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    random_index <span class="op">=</span> np.random.choice(<span class="bu">len</span>(sample_out))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the image at the selected index</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    ax.imshow(sample_x[random_index].view(<span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the true label and predicted label for the selected index</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> sample_y[random_index]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    guess_label <span class="op">=</span> sample_out.argmax(<span class="dv">1</span>)[random_index]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the title of the subplot with the true and predicted labels</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Guess: </span><span class="sc">{</span>classes[guess_label]<span class="sc">}</span><span class="ss">, True: </span><span class="sc">{</span>classes[true_label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Turn off axis for better visualization</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a title to the entire figure</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Forward Propagation"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="01_linearlayer_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>Forward Propagation</strong>, giống như tên của nó, là quá trình diễn ra từ đầu vào đến đầu ra mục tiêu mà không quan tâm đến kết quả cuối cùng.</p>
<p>Để hình dung, hãy nghĩ về việc bạn đang làm một bài thi. Trong quá trình bạn làm xong bài đó tới khi hết giờ, bạn không cần biết điểm cuối cùng của mình sẽ là bao nhiêu. Forward Propagation chính là giai đoạn này trong Deep Learning, nó là bước đầu tiên và quan trọng nhất trong việc tính toán dự đoán của mô hình trước khi xem xét các bước sau như tính toán loss và cập nhật trọng số trong quá trình huấn luyện.</p>
</section>
<section id="loss-function" class="level2">
<h2 class="anchored" data-anchor-id="loss-function">Loss Function</h2>
<p>Trong Deep Learning, có 3 hàm Loss Function rất phổ biến và thường được sử dụng trong hầu hết các dự án:</p>
<ul>
<li><p>Binary Cross-Entropy (BCE) Loss</p></li>
<li><p>Mean Squared Error (MSE) Loss</p></li>
<li><p>Cross-Entropy Loss</p></li>
</ul>
<p>Sự lựa chọn giữa các hàm Loss Function này phụ thuộc vào mục tiêu cụ thể của mỗi dự án.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>loss_fn_bce <span class="op">=</span> nn.BCELoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Binary Cross-Entropy (BCE) Loss:</strong> Thường được sử dụng trong các nhiệm vụ phân loại nhị phân. BCE Loss giúp đo lường mức độ sai lệch giữa dự đoán và thực tế khi chỉ có hai lớp đối tượng.</p>
<p>Để hình dung, hãy tưởng tượng hôm nay là những ngày cuối năm học, bạn đã thu thập tất cả các điểm thi của mình (là đầu vào), và bạn muốn sử dụng những điểm số này để dự đoán xem liệu bạn có đủ điểm để được xếp vào danh sách “Học sinh Giỏi” hay “không”. Trong tình huống này, bạn sẽ nên sử dụng Binary Cross-Entropy Loss để đo lường sự chênh lệch giữa dự đoán của bạn và thực tế. BCE Loss giúp bạn đánh giá mức độ “đúng” của dự đoán dựa trên hai khả năng: “có” hoặc “không có” danh hiệu Học sinh Giỏi.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>loss_fn_ce <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Cross-Entropy Loss:</strong> Thường được sử dụng trong các tác vụ phân loại đa lớp. CE Loss giúp đo độ khác biệt giữa phân phối xác suất của dự đoán và phân phối xác suất thực tế của các lớp.</p>
<p>Để hình dung, (giống như ví dụ trước) hôm nay là những ngày cuối năm học và đã thu thập tất cả điểm số từ các kỳ thi của mình (đây là dữ liệu đầu vào). Thay vì bạn chỉ quan tâm đến việc bạn có đủ điểm để được xếp hạng Giỏi hay không, bạn muốn biết chính xác bạn thuộc loại Giỏi, Khá, Trung bình. Trong tình huống này, bạn sẽ nên sử dụng Cross-Entropy Loss để đánh giá mức độ khác biệt giữa dự đoán của bạn và thực tế. CE Loss giúp bạn đo đạc mức độ “đúng” của dự đoán dựa trên khả năng phân loại chính xác vào từng loại danh hiệu học tập khác nhau, chẳng hạn như Giỏi, Khá, và Trung bình.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>loss_fn_mse <span class="op">=</span> nn.MSELoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Mean Squared Error (MSE) Loss:</strong> Thường được ưa chuộng trong các tác vụ dự đoán và hồi quy. MSE Loss đo độ lớn của sai số bình phương giữa dự đoán và giá trị thực tế. Ví dụ như là dự đoán giá nhà, dự đoán giá sản phẩm.</p>
<p>Để hình dung, (giống như ví dụ trước) hôm nay là những ngày cuối năm học và đã thu thập tất cả điểm số từ các kỳ thi của mình (đây là dữ liệu đầu vào). Thay vì chỉ quan tâm đến việc bạn có đủ điểm để được xếp hạng Giỏi, Khá, hay Trung bình, bạn muốn biết chính xác điểm tổng kết năm học của bạn sẽ là bao nhiêu. Trong tình huống này, bạn sẽ nên sử dụng Mean Squared Error (MSE) Loss để đánh giá mức độ khác biệt giữa dự đoán của bạn và thực tế. MSE Loss giúp bạn đo đạc mức độ sai lệch bình phương giữa dự đoán và điểm tổng kết thực tế, cho phép bạn biết được mức độ chính xác của dự đoán về điểm số.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Converting the data type of sample_y to Long.</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>sample_y <span class="op">=</span> sample_y.to(torch.<span class="bu">long</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>sample_loss <span class="op">=</span> loss_fn(sample_out, sample_y)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>sample_loss<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>sample_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 15.463730812072754</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor(15.4637, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<p>Trong dự án Fashion MNIST này, với mục tiêu là phân loại thành 10 nhãn, việc sử dụng <strong>Cross-Entropy Loss</strong> là lựa chọn phù hợp nhất.</p>
<p>Hàm CrossEntropyLoss trong PyTorch đòi hỏi đầu vào y_true (targets) phải có kiểu dữ liệu là Long (integer) và chứa các nhãn thực tế, cùng với dự đoán (output prediction) của mô hình.</p>
</section>
<section id="optimization-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="optimization-algorithms">Optimization Algorithms</h2>
<p>Có 3 thuật toántối ưu hóa phổ biến trong giảng dạy, thử nghiệm và cải thiện mô hình:</p>
<ul>
<li><p><strong>SGD</strong>: Stochastic Gradient Descent</p></li>
<li><p><strong>Adam</strong>: Adaptive Moment Estimation</p></li>
<li><p><strong>RMSProp</strong>: Root Mean Square Propagation</p></li>
</ul>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> [weight, bias]</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">.01</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SGD</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>optimizer_sgd <span class="op">=</span> torch.optim.SGD(parameters, lr <span class="op">=</span> learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>SGD (Stochastic Gradient Descent)</strong> có thể coi là một trong những thuật toán tối ưu hóa (optimizer) cơ bản nhất trong Deep Learning. Nó tương tự như Linear Layer, được xem như một trong những nền tảng cơ bản nhất để phát triển mô hình Neural Network trong Deep Learning. SGD cung cấp một nền tảng quan trọng để từ đó các thuật toán tối ưu hóa nâng cao như Adam và RMSProp được phát triển và hoạt động</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> [weight, bias]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">.01</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSProp </span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>optimizer_rms <span class="op">=</span> torch.optim.RMSprop(parameters, lr <span class="op">=</span> learning_rate) </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Adam</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>optimizer_adam <span class="op">=</span> torch.optim.Adam(parameters, lr <span class="op">=</span> learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Adam</strong> và <strong>RMSProp</strong> có thể được xem là những thuật toán tối ưu hóa (optimizer) tiến bộ hơn của SGD trong Deep Learning. Chúng thường giúp cho mô hình học nhanh và hiệu quả hơn.</p>
<p>Để dễ hình dung, hãy nghĩ đến một tình huống trong đó bạn cần ôn thi với một đề cương dày đặc. Thay vì phải đọc toàn bộ đề cương, điều này có thể mất nhiều thời gian, bạn quyết định sử dụng một phương pháp thông minh hơn. Bạn tập trung vào việc học các từ khóa chính của từng câu hỏi trong đề cương. Bằng cách này, bạn vẫn có thể đạt điểm cao trong kì thi nhưng tiết kiệm được rất nhiều thời gian.</p>
<p>Tương tự, Adam và RMSProp giúp mô hình Deep Learning tập trung vào những điểm quan trọng trong quá trình học, điều này giúp cải thiện hiệu suất huấn luyện và tiết kiệm thời gian so với việc sử dụng SGD truyền thống.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> [weight, bias]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">.01</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use Adam</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(parameters, lr <span class="op">=</span> learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Trước tiên, tôi sẽ tiến hành thử nghiệm mô hình bằng cách sử dụng thuật toán <strong>Adam</strong>. Sau khi đã tiến đến giai đoạn kiểm tra và có cái nhìn tổng quan về hiệu suất của mô hình, tôi sẽ xem xét việc tối ưu hóa mô hình bằng cách thử nghiệm với RMSProp optimizer.</p>
</section>
<section id="backward-propagation" class="level2">
<h2 class="anchored" data-anchor-id="backward-propagation">Backward Propagation</h2>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss Before Backward: </span><span class="sc">{</span>sample_loss<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Backward Propagation </span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    sample_loss.backward()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update parameters</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward Propagation</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    sample_out <span class="op">=</span> sample_x <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    sample_loss <span class="op">=</span> loss_fn(sample_out, sample_y)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss After Backward: </span><span class="sc">{</span>sample_loss<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss Before Backward: 15.463730812072754
Loss After Backward: 13.028249740600586

Loss Before Backward: 13.028249740600586
Loss After Backward: 10.919900894165039
</code></pre>
</div>
</div>
<p><strong>Backpropagation</strong> là quá trình quan trọng trong huấn luyện mạng neural để giảm thiểu độ lỗi (loss), tức là để đưa ra các dự đoán (predictions) gần giống với các giá trị thực tế (labels). Nó cho phép mô hình của bạn hiệu quả hơn trong việc dự đoán kết quả dựa trên dữ liệu đầu vào.</p>
<p>Thuật toán chính được sử dụng để điều chỉnh các tham số của mạng neural trong quá trình này gọi là <strong>Gradient Descent</strong>. Cụ thể, bạn tính toán độ dốc (gradient) của mỗi tham số, sau đó điều chỉnh các tham số đó bằng cách trừ một lượng nhất định (được điều chỉnh bởi <strong>learning rate</strong>) nhân với độ dốc (gradient). Quá trình này được lặp lại nhiều lần để dần dần cải thiện khả năng dự đoán của mô hình.</p>
<p>Vì vậy, tổng hợp lại, <strong>Backpropagation</strong> là quá trình tối ưu hóa mô hình thông qua <strong>Gradient Descent</strong>, giúp mô hình học từ dữ liệu và dự đoán chính xác hơn kết quả mà bạn mong muốn bằng cách điều chỉnh các tham số dựa trên độ dốc (gradient) và <strong>Learning Rate</strong> của loss function.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Epoch</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Backward Propagation </span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    sample_loss.backward()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update parameters</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward Propagation</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    sample_out <span class="op">=</span> sample_x <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    sample_loss <span class="op">=</span> loss_fn(sample_out, sample_y)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>sample_loss<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0: 9.452093124389648
Epoch 1: 8.548746109008789
Epoch 2: 7.9047627449035645</code></pre>
</div>
</div>
<p>Hãy tưởng tượng rằng bạn đang tham gia vào một cuộc thi để cố gắng đạt được điểm số cao nhất mà bạn có thể. Hãy xem xét quy trình sau:</p>
<p>Bước 1 - <strong>Forward</strong>: Lần đầu tiên khi bạn bắt đầu làm bài thi, bạn chỉ cố gắng làm xong tất cả các phần của bài thi mà không quan tâm đến điểm số cuối cùng. Trong ngữ cảnh của deep learning, điều này tương đương với việc sử dụng dữ liệu đầu vào để tính toán và tạo ra một đầu ra dự đoán.</p>
<p>Bước 2 - <strong>Loss</strong>: Sau khi bạn đã hoàn thành bài thi, bạn nhận được điểm số của mình từ giáo viên. Lúc này, bạn có thể so sánh điểm số này với điểm số tối đa có thể đạt được trong bài thi đó. Sự khác biệt giữa điểm số của bạn và điểm số tối đa đó được gọi là loss. Trong Deep Learning, Loss là một số đo lường sự sai khác giữa đầu ra dự đoán và đầu ra thực tế mà chúng ta muốn.</p>
<p>Bước 3 - <strong>Backward</strong>: Với thông tin về loss, bạn bắt đầu nghiên cứu và học từ những câu hỏi hoặc phần của bài thi mà bạn đã trả lời sai hoặc không chắc chắn. Bạn cố gắng hiểu rõ hơn về chúng và cách cải thiện kết quả của mình. Trong deep learning, quá trình này được gọi là backward hoặc backpropagation. Nó giúp điều chỉnh các tham số trong neural network để giảm thiểu loss.</p>
<p><strong>Epoch (chu kỳ)</strong>: Mỗi lần bạn thực hiện quá trình từ “Forward” đến “Backward” từ đầu đến cuối, đó là một chu kỳ hoàn chỉnh (1 epoch) trong cuộc thi của bạn, và được gọi là một “Epoch.”</p>
<p>Vậy, trong bối cảnh của deep learning, một “Epoch” là một chu kỳ hoàn chỉnh của quá trình huấn luyện mô hình, bao gồm Forward, tính toán Loss, và Backward để cải thiện mô hình. Việc lặp lại nhiều Epochs giúp mô hình học được từ dữ liệu và cải thiện khả năng dự đoán của nó.</p>
</section>
<section id="altogether" class="level2">
<h2 class="anchored" data-anchor-id="altogether">Altogether</h2>
<section id="use-sample-data" class="level3">
<h3 class="anchored" data-anchor-id="use-sample-data">Use Sample Data</h3>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a first mini batch of data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>sample_x, sample_y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape and cast the input data</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>sample_x <span class="op">=</span> sample_x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>sample_x <span class="op">=</span> sample_x.to(torch.float32)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Cast the target labels to the 'long' data type</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>sample_y <span class="op">=</span> sample_y.to(torch.<span class="bu">long</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample_x.shape, sample_y.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([128, 784]) torch.Size([128])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(<span class="bu">input</span>, targets, loss_fn, optimizer_algorithm, lr, n_epochs):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize weights and bias</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    weight <span class="op">=</span> torch.randn(<span class="dv">784</span>, <span class="dv">10</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    bias <span class="op">=</span> torch.zeros(<span class="dv">10</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the optimizer function based on the provided algorithm name</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    opt_fn <span class="op">=</span> <span class="bu">getattr</span>(torch.optim, optimizer_algorithm)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> opt_fn([weight, bias], lr<span class="op">=</span>lr)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Lists to store losses and training accuracy</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> []</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">=</span> []</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="bu">input</span> <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate loss</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(out, targets)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the loss</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate training accuracy</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (out.argmax(<span class="dv">1</span>) <span class="op">==</span> targets).<span class="bu">float</span>().mean()</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        train_acc.append(acc)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out, losses, train_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the loss function (CrossEntropyLoss) and optimizer algorithm (Adam)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>optimizer_algorithm <span class="op">=</span> <span class="st">"Adam"</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the learning rate and number of training epochs</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the 'train_model' function to train the model</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>out, losses, train_acc <span class="op">=</span> train_model(sample_x, sample_y, loss_fn, optimizer_algorithm, learning_rate, n_epochs)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the final loss and training accuracy</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>final_loss <span class="op">=</span> losses[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>final_accuracy <span class="op">=</span> train_acc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Print or use the final_loss and final_accuracy as needed</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Final Loss: </span><span class="sc">{</span>final_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Final Training Accuracy: </span><span class="sc">{</span>final_accuracy<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Loss: 1.8055
Final Training Accuracy: 64.84%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize <span class="op">=</span> (<span class="dv">14</span>, <span class="dv">3</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(losses)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="ss">f"Epoch </span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, Loss is: </span><span class="sc">{</span>final_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(train_acc)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="ss">f"Epoch </span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">, Accuracy is: </span><span class="sc">{</span>final_accuracy<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">"Accuracy"</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="01_linearlayer_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>ids_error <span class="op">=</span> (out.argmax(<span class="dv">1</span>) <span class="op">!=</span> sample_y).nonzero()</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"In </span><span class="sc">{</span><span class="bu">len</span>(sample_y)<span class="sc">}</span><span class="ss"> images, model guess wrong </span><span class="sc">{</span><span class="bu">len</span>(ids_error)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>In 128 images, model guess wrong 45</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axs.flatten():</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select a random index from the output</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    random_index <span class="op">=</span> np.random.choice(<span class="bu">len</span>(out))</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the image at the selected index with colormap gray for correct predictions</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> sample_y[random_index]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    guess_label <span class="op">=</span> out.argmax(<span class="dv">1</span>)[random_index]</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> true_label <span class="op">==</span> guess_label:</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        ax.imshow(sample_x[random_index].view(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>        ax.imshow(sample_x[random_index].view(<span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Guess: </span><span class="sc">{</span>classes[guess_label]<span class="sc">}</span><span class="ss">, True: </span><span class="sc">{</span>classes[true_label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Result"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="01_linearlayer_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="use-all-data" class="level3">
<h3 class="anchored" data-anchor-id="use-all-data">Use All Data</h3>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(train_loader, valid_loader, loss_fn, optimizer_algorithm, lr, n_epochs):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize weights and bias</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    weight <span class="op">=</span> torch.randn(<span class="dv">784</span>, <span class="dv">10</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    bias <span class="op">=</span> torch.zeros(<span class="dv">10</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the optimizer function based on the provided algorithm name</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    opt_fn <span class="op">=</span> <span class="bu">getattr</span>(torch.optim, optimizer_algorithm)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> opt_fn([weight, bias], lr<span class="op">=</span>lr)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Lists to store losses and training accuracy</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> torch.zeros(n_epochs, <span class="bu">len</span>(train_loader))</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">=</span> torch.zeros(n_epochs, <span class="bu">len</span>(train_loader))</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    valid_acc <span class="op">=</span> torch.zeros(n_epochs, <span class="bu">len</span>(valid_loader))</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Reshape and cast the input data</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.to(torch.float32)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Cast the target labels to the 'long' data type</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> y.to(torch.<span class="bu">long</span>)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass</span></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> x <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate loss</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(out, y)</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Backpropagation</span></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store the loss</span></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>            losses[epoch, i] <span class="op">=</span> loss.item()</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate training accuracy</span></span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (out.argmax(<span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">float</span>().mean()</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>            train_acc[epoch, i] <span class="op">=</span> acc</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Evaluation in test data</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> j, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(valid_loader):</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>                    x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>                    x <span class="op">=</span> x.to(torch.float32)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Cast the target labels to the 'long' data type</span></span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>                    y <span class="op">=</span> y.to(torch.<span class="bu">long</span>)</span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> x <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>                    acc <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (out.argmax(<span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">float</span>().mean()</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>                    valid_acc[epoch, j] <span class="op">=</span> acc</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [weight, bias], losses, train_acc, valid_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the start time</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the loss function (CrossEntropyLoss) and optimizer algorithm (Adam)</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>optimizer_algorithm <span class="op">=</span> <span class="st">"Adam"</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the learning rate and number of training epochs</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the 'train_model' function to train the model with all data</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>parameters, losses, train_acc, valid_acc <span class="op">=</span> train_model(train_loader, <span class="op">\</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>                                                       valid_loader, <span class="op">\</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>                                                       loss_fn, <span class="op">\</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>                                                       optimizer_algorithm, <span class="op">\</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>                                                       learning_rate, <span class="op">\</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>                                                       n_epochs)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the end time</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the execution time</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to minutes and seconds</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>execution_time_minutes <span class="op">=</span> <span class="bu">int</span>(execution_time <span class="op">//</span> <span class="dv">60</span>)</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>execution_time_seconds <span class="op">=</span> <span class="bu">round</span>(execution_time <span class="op">%</span> <span class="dv">60</span>, <span class="dv">2</span>) </span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model training time: </span><span class="sc">{</span>execution_time_minutes<span class="sc">}</span><span class="ss"> min </span><span class="sc">{</span>execution_time_seconds<span class="sc">}</span><span class="ss">s"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model training time: 8 min 34.2s</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>final_loss <span class="op">=</span> losses.mean(<span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>final_train_acc <span class="op">=</span> train_acc.mean(<span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>final_valid_acc <span class="op">=</span> valid_acc.mean(<span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize <span class="op">=</span> (<span class="dv">14</span>, <span class="dv">3</span>))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(<span class="bu">range</span>(losses.shape[<span class="dv">0</span>]), losses.mean(<span class="dv">1</span>), <span class="st">"-o"</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="ss">f"Train Loss is: </span><span class="sc">{</span>final_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(<span class="bu">range</span>(train_acc.shape[<span class="dv">0</span>]), train_acc.mean(<span class="dv">1</span>), <span class="st">"-o"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(<span class="bu">range</span>(valid_acc.shape[<span class="dv">0</span>]), valid_acc.mean(<span class="dv">1</span>), <span class="st">"-o"</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="ss">f"Train: </span><span class="sc">{</span>final_train_acc<span class="sc">:.2f}</span><span class="ss">%, Valid: </span><span class="sc">{</span>final_valid_acc<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].legend([<span class="st">"Train"</span>, <span class="st">"Valid"</span>])</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f"Result with Linear Layer"</span>, fontsize <span class="op">=</span> <span class="dv">16</span>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="01_linearlayer_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Kết quả cũng khá cao, hơn 80% trên tập dữ liệu validation bằng mô hình Linear Layer (mô hình neural đơn giản nhất) sau 5 epochs. Bây giờ, hãy cùng kiểm tra để xem liệu chúng ta có thể đạt được bao nhiêu phần trăm độ chính xác trên tập dữ liệu kiểm tra (test set).</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> test_dataset.data</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> test_dataset.targets</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape and cast the input data</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.to(torch.float32)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>x_test_norm <span class="op">=</span> min_max_scale(x_test)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Cast the target labels to the 'long' data type</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y_test.to(torch.<span class="bu">long</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>weight <span class="op">=</span> parameters[<span class="dv">0</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> parameters[<span class="dv">1</span>]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> x_test_norm <span class="op">@</span> weight <span class="op">+</span> bias</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>test_acc <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (out.argmax(<span class="dv">1</span>) <span class="op">==</span> y_test).<span class="bu">float</span>().mean()</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>ids_error <span class="op">=</span> (out.argmax(<span class="dv">1</span>) <span class="op">!=</span> y_test).nonzero()</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"In </span><span class="sc">{</span><span class="bu">len</span>(y_test)<span class="sc">}</span><span class="ss"> images, model guess wrong </span><span class="sc">{</span><span class="bu">len</span>(ids_error)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy is: </span><span class="sc">{</span>test_acc<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>In 10000 images, model guess wrong 1952
Accuracy is: 80.48%</code></pre>
</div>
</div>
<p>Với mô hình Linear Layer và 5 epochs, chúng ta đã đạt được độ chính xác xấp xỉ 80% trên tập dữ liệu kiểm tra (test set). Giờ hãy thử sử dụng một mạng neural (neural network) để xem liệu chúng ta có thể đạt được độ chính xác cao hơn không! Hãy cùng chờ xem kết quả sẽ thế nào!</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axs.flatten():</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select a random index from the output</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    random_index <span class="op">=</span> np.random.choice(<span class="bu">len</span>(out))</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the image at the selected index with colormap gray for correct predictions</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> y_test[random_index]</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    guess_label <span class="op">=</span> out.argmax(<span class="dv">1</span>)[random_index]</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> true_label <span class="op">==</span> guess_label:</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        ax.imshow(x_test[random_index].view(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>        ax.imshow(x_test[random_index].view(<span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Guess: </span><span class="sc">{</span>classes[guess_label]<span class="sc">}</span><span class="ss">, True: </span><span class="sc">{</span>classes[true_label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Result"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="01_linearlayer_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>